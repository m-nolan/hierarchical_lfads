{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform == 'win32':\n",
    "    dataset_dir = 'D:/Users/mickey/Data/datasets/ecog/goose_wireless'\n",
    "elif sys.platform == 'linux':\n",
    "    dataset_dir = '/home/ws5/manolan/data/datasets/ecog/goose_wireless'\n",
    "assert os.path.exists(dataset_dir), f'{dataset_dir} not found!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_suffix = '_fl50u120'\n",
    "parent_dataset = 'gw_250' + data_suffix\n",
    "full_dataset_h5f = h5py.File(os.path.join(dataset_dir,parent_dataset),mode='r')\n",
    "with open(os.path.join(dataset_dir,f'{parent_dataset}_param.pkl'),mode='rb') as pf:\n",
    "    full_dataset_param_dict = pkl.load(pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create smaller dataset, randomly sampling from each portion\n",
    "factor = 5\n",
    "frac_train_size = full_dataset_h5f['train_ecog'+data_suffix].shape[0]//factor\n",
    "frac_valid_size = full_dataset_h5f['valid_ecog'+data_suffix].shape[0]//factor\n",
    "frac_test_size = full_dataset_h5f['test_ecog'+data_suffix].shape[0]//factor\n",
    "frac_train_idx = np.random.permutation(full_dataset_h5f['train_ecog'+data_suffix].shape[0])[:frac_train_size]\n",
    "frac_valid_idx = np.random.permutation(full_dataset_h5f['valid_ecog'+data_suffix].shape[0])[:frac_valid_size]\n",
    "frac_test_idx = np.random.permutation(full_dataset_h5f['test_ecog'+data_suffix].shape[0])[:frac_test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset and parameter pickle (same as the full set, I didn't actually save the sample order in the original).\n",
    "frac_dataset_h5f = h5py.File(os.path.join(dataset_dir,f'gw_250'+data_suffix+f'_dec{factor}'),mode='w')\n",
    "frac_dataset_h5f['train_ecog'+data_suffix] = full_dataset_h5f['train_ecog'+data_suffix].value[frac_train_idx,:,:]\n",
    "frac_dataset_h5f['valid_ecog'+data_suffix] = full_dataset_h5f['valid_ecog'+data_suffix].value[frac_valid_idx,:,:]\n",
    "frac_dataset_h5f['test_ecog'+data_suffix] = full_dataset_h5f['test_ecog'+data_suffix].value[frac_test_idx,:,:]\n",
    "frac_dataset_h5f['dt'] = full_dataset_h5f['dt'][()]\n",
    "with open(os.path.join(dataset_dir,'gw_250'+data_suffix+'_pilot_param.pkl'),mode='wb') as pf:\n",
    "    pkl.dump(full_dataset_param_dict,pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_h5f.close()\n",
    "frac_dataset_h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frac_train_size,frac_valid_size,frac_test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecog_is2s",
   "language": "python",
   "name": "ecog_is2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
