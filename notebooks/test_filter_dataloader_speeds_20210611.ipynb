{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0a8b1621963cf260009cce534265ebd329ad9e92f76229299bf2e2f323a893fa1",
   "display_name": "Python 3.7.6 64-bit ('ecog_is2s': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import site\n",
    "site.addsitedir(r'D:\\Users\\mickey\\aoLab\\code\\hierarchical_lfads')\n",
    "from dataset import EcogTensorDataset, MultiblockEcogTensorDataset, FilterData, create_n_block_w\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from utils import read_data, read_multiband_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_record_path = r'D:\\Users\\mickey\\Data\\datasets\\ecog\\goose_wireless\\gw_250_renorm'\n",
    "filt_record_path = r'D:\\Users\\mickey\\Data\\datasets\\ecog\\goose_wireless\\gw_250_nband2'\n",
    "full_record = h5py.File(full_record_path,mode='r')\n",
    "filt_record = h5py.File(filt_record_path,mode='r')\n",
    "full_dict = {'test_ecog': full_record['test_ecog'][()]}\n",
    "filt_dict = {'band0_test_ecog': filt_record['band0_test_ecog'][()],\n",
    "             'band1_test_ecog': filt_record['band1_test_ecog'][()]}\n",
    "n_block = 2\n",
    "device = 'cuda'\n",
    "# create h5 dataset\n",
    "h5_ds = MultiblockEcogTensorDataset(full_record,filt_record,n_band=n_block,part_str='test',device=device)\n",
    "# create dict dataset\n",
    "dict_ds = MultiblockEcogTensorDataset(full_dict,filt_dict,n_band=n_block,part_str='test',device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_index = 1000\n",
    "t_h5 = []\n",
    "t_dict = []\n",
    "for idx in tqdm(range(n_index)):\n",
    "    #   h5 dataset sampling\n",
    "    t_h5_start = time.time()\n",
    "    h5_sample = h5_ds.__getitem__(idx)\n",
    "    t_h5_end = time.time()\n",
    "    t_h5.append(t_h5_end - t_h5_start)\n",
    "    #   dict dataset sampling\n",
    "    t_dict_start = time.time()\n",
    "    dict_sample = dict_ds.__getitem__(idx)\n",
    "    t_dict_end = time.time()\n",
    "    t_dict.append(t_dict_end-t_dict_start)\n",
    "t_h5 = np.array(t_h5)\n",
    "t_dict = np.array(t_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(t_h5),np.std(t_h5))\n",
    "print(np.mean(t_dict),np.std(t_dict))\n",
    "plt.hist(t_h5,100,label='h5')\n",
    "plt.hist(t_dict,100,label='dict')\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{t_h5.mean():0.3e}\\t{t_h5.var():0.3e}\\t[{np.percentile(t_h5,[2.5,97.5])}]')\n",
    "print(f'{t_dict.mean():0.3e}\\t{t_dict.var():0.3e}\\t[{np.percentile(t_dict,[2.5,97.5])}]')"
   ]
  },
  {
   "source": [
    "SO - the dict loader is ~2x the speed of the record loader. If you CAN load all your training/validation data into CPU-side memory, do it. If you can't, it will take on average 2x the time to process each epoch with this implementation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}