{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('ecog_is2s': conda)",
   "metadata": {
    "interpreter": {
     "hash": "fe8054fe0736511d0a995e424bd42fab5ba13013efdf79ed2907f82c79967e8d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import site\n",
    "site.addsitedir(os.path.curdir + '\\..')\n",
    "from analysis import *\n",
    "import scipy as sp\n",
    "# ^ this has all of the analysis functions from the prior notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter_path = \"C:\\\\Users\\\\mickey\\\\aoLab\\\\code\\\\hierarchical_lfads\\\\hyperparameters\\\\ecog\\\\lfads_ecog_4.yaml\"\n",
    "# data_path = \"D:\\\\Users\\\\mickey\\\\Data\\\\datasets\\\\ecog\\\\goose_wireless\\\\gw_250_fl0u10\"\n",
    "data_path = \"D:\\\\Users\\\\mickey\\\\Data\\\\datasets\\\\ecog\\\\goose_wireless\\\\gw_250\"\n",
    "overwrite = False\n",
    "# assert os.path.exists(hyperparameter_path), \"hyperparameter file not found.\"\n",
    "assert os.path.exists(data_path), \"data file not found.\"\n",
    "# model_dir = \"D:\\\\Users\\\\mickey\\\\Data\\\\models\\\\pyt\\\\lfads\\\\gw_250_fl0u10\\\\lfads_ecog\\\\\"\n",
    "model_dir = \"D:\\\\Users\\\\mickey\\\\Data\\\\models\\\\pyt\\\\lfads\\\\gw_250\\\\lfads_ecog\\\\\"\n",
    "# model_dir_list = glob(os.path.join(model_dir,\"cenc0_cont0_fact128_genc256_gene256_glat256_nch*_seqlen*_ulat0_orion-l1\"))\n",
    "# model_dir_list = glob(os.path.join(model_dir,\"cenc0_cont0_fact64_genc256_gene256_glat256_nch*_seqlen*_ulat0_orion-\"))\n",
    "# model_dir_list = glob(os.path.join(model_dir,\"cenc0_cont0_fact128_genc1024_gene1024_glat1024_nch*_seqlen*_ulat0_orion-\"))\n",
    "model_dir_list = glob(os.path.join(model_dir,\"cenc0_cont0_fact64_genc1024_gene1024_glat1024_nch42_seqlen50_ulat0_orion-varstd\"))\n",
    "# model_dir_list = list(set(model_dir_list) | set(glob(os.path.join(model_dir,\"cenc0_cont0_fact128_genc1024_gene1024_glat1024_nch*_seqlen*_ulat0_orion-\"))))\n",
    "metric_stat_table_file = os.path.join(model_dir,\"stat_table_freq.csv\")\n",
    "if os.path.exists(metric_stat_table_file) and not overwrite:\n",
    "    metric_stat_table = pd.read_csv(metric_stat_table_file)\n",
    "    run_model_dir_list = list(metric_stat_table['model_path'])\n",
    "    model_dir_list = list(set(model_dir_list) - set(run_model_dir_list))\n",
    "    metric_stat_table = [pd.read_csv(metric_stat_table_file)]\n",
    "else:\n",
    "    metric_stat_table = []\n",
    "print(f\"unassessed models found:\\t{len(model_dir_list)}\")\n",
    "print(model_dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trace = 6\n",
    "srate = 250\n",
    "n_boot = 500\n",
    "metric_list = []\n",
    "ar_model_path = 'D:\\\\Users\\\\mickey\\\\Data\\\\analysis\\\\ar_valid_set\\\\ar_model_dict.pkl'\n",
    "model_perf_table = 'D:\\\\Users\\\\mickey\\\\Data\\\\analysis\\\\freq-band-test\\\\stat_table.csv'\n",
    "with open(ar_model_path,'rb') as f:\n",
    "    ar_model_dict = pkl.load(f)\n",
    "for model_dir in tqdm(model_dir_list[:1]):\n",
    "    hyperparameter_path = os.path.join(model_dir,'hyperparameters.yaml')\n",
    "    print(f'loading model from:\\t{model_dir}')\n",
    "    model, test_data, test_data_mask = load_configure_model_data(model_dir,data_path,hyperparameter_path)\n",
    "    b_lp, a_lp = sp.signal.iirfilter(10,40./(250/2),btype='lowpass')\n",
    "    # b_hp, a_hp = sp.signal.iirfilter(10,40./(250/2),btype='highpass')\n",
    "    test_data = np.float32(sp.signal.filtfilt(b_lp, a_lp, test_data, axis=1))\n",
    "    # test_data = np.float32(sp.signal.filtfilt(b_hp, a_hp, test_data, axis=1))\n",
    "    test_data = test_data[np.any(test_data.std(axis=1)>0.5,axis=-1),:,:]\n",
    "    # test_data = sp.stats.zscore(test_data,axis=1)\n",
    "    print('computing test data reconstructions...')\n",
    "    recon, _, _ = compute_model_outputs(model,torch.tensor(test_data))\n",
    "    print('computing metric statistics...')\n",
    "    stat_table, metric_dict = compute_metric_table(test_data,recon,model_dir)\n",
    "# if os.path.exists(model_perf_table):\n",
    "#     stat_table.to_csv(model_perf_table,mode='a',header=False)\n",
    "# else:\n",
    "#     stat_table.to_csv(model_perf_table,mode='w',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = test_data - np.array(recon['data'])\n",
    "# err_lf = test_data_lf - np.array(recon_lf['data'])\n",
    "# err_hf = test_data_hf - np.array(recon_hf['data'])\n",
    "# test_data.shape\n",
    "test_hat = np.fft.rfft(test_data,axis=1)\n",
    "# test_lf_hat = np.fft.rfft(test_data_hf,axis=1)\n",
    "# test_hf_hat = np.fft.rfft(test_data_hf,axis=1)\n",
    "recon_hat = np.fft.rfft(np.array(recon['data']),axis=1)\n",
    "# recon_lf_hat = np.fft.rfft(np.array(recon_lf['data']),axis=1)\n",
    "# recon_hf_hat = np.fft.rfft(np.array(recon_hf['data']),axis=1)\n",
    "err_hat = np.fft.rfft(err,axis=1)\n",
    "# err_lf_hat = np.fft.rfft(err_lf,axis=1)\n",
    "# err_hf_hat = np.fft.rfft(err_hf,axis=1)\n",
    "freq = np.fft.rfftfreq(50,d=1/srate)\n",
    "time = np.arange(50)/srate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_idx = np.random.randint(0,high=test_data.shape[0])\n",
    "fig, ax = plt.subplots(3,1,dpi=150,constrained_layout=True)\n",
    "ax = ax.reshape(-1)\n",
    "ax[0].plot(time,test_data[trial_idx,:,0],label='data')\n",
    "ax[0].plot(time,recon['data'][trial_idx,:,0],label='recon.')\n",
    "ax[0].plot(time,err[trial_idx,:,0],label='err')\n",
    "ax[0].set_xlabel('time (s)')\n",
    "ax[0].legend(loc=0)\n",
    "ax[1].plot(freq,20*np.log10(np.abs(test_hat[trial_idx,:,0])))\n",
    "ax[1].plot(freq,20*np.log10(np.abs(recon_hat[trial_idx,:,0])))\n",
    "ax[1].plot(freq,20*np.log10(np.abs(err_hat[trial_idx,:,0])))\n",
    "ax[1].set_xlabel('freq. (Hz)')\n",
    "# ax[2].plot(freq,np.angle(test_hat[trial_idx,:,0]))\n",
    "# ax[2].plot(freq,np.angle(recon_hat[trial_idx,:,0]))\n",
    "# ax[2].plot(freq,np.angle(err_hat[trial_idx,:,0]))\n",
    "ax[2].plot(freq,20*(np.log10(np.abs(err_hat[trial_idx,:,0]))-np.log10(np.abs(test_hat[trial_idx,:,0]))))\n",
    "ax[2].set_title('Normalized Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that's a good plot: let's look at the distribution of all these normalized error values\n",
    "f_est = lambda x: np.nanmean(x,axis=(0,2))\n",
    "# data\n",
    "test_hat_bsd = bootstrap_est(test_hat,n_boot,f_est)\n",
    "test_hat_mean = np.nanmean(test_hat_bsd,axis=0)\n",
    "test_hat_ci = np.nanpercentile(test_hat_bsd,[2.5,97.5],axis=0)\n",
    "# reconstruction\n",
    "recon_hat_bsd = bootstrap_est(recon_hat,n_boot,f_est)\n",
    "# normalized error\n",
    "norm_err_hat = np.log10(np.abs(err_hat)) - np.log10(np.abs(test_hat))\n",
    "norm_err_hat[np.isposinf(norm_err_hat)] = np.nan\n",
    "norm_err_hat_bsd = bootstrap_est(norm_err_hat,n_boot,f_est)\n",
    "norm_err_hat_mean = np.nanmean(norm_err_hat_bsd,axis=0)\n",
    "norm_err_hat_ci = np.nanpercentile(norm_err_hat_bsd,[2.5,97.5],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(freq,20*norm_err_hat_ci[0,:],20*norm_err_hat_ci[1,:],alpha=0.3)\n",
    "plt.plot(freq,20*norm_err_hat_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_lp, a_lp = sp.signal.iirfilter(10,40./(250/2),btype='lowpass')\n",
    "b_hp, a_hp = sp.signal.iirfilter(10,40./(250/2),btype='highpass')\n",
    "test_data_lp = sp.signal.filtfilt(b_lp, a_lp, test_data, axis=1)\n",
    "test_data_hp = sp.signal.filtfilt(b_hp, a_hp, test_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time,test_data[0,:,14])\n",
    "plt.plot(time,test_data_lp[0,:,14])\n",
    "plt.plot(time,test_data_hp[0,:,14])"
   ]
  }
 ]
}